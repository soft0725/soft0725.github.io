---
title: 모딥 시즌 1 - ML lec 05-1
date: '2023-07-24 22:50:00 +0900'
categories: [DeepLearning, 모두를 위한 딥러닝 시즌 1]
tags: [모두를 위한 딥러닝 시즌 1]
math: true
---

# lec 05 정리

이번 블로그에서는 Logistic classification에 대해서 공부할 것이다.  
하지만 이것을 공부하기 전에 원래 공부했던 Linear regression을 복습하고 어떻게 다른지 알아보도록 하자.  


## Linear regression 복습 

### 간단하게 정리하면 이렇다.

먼저 Linear regression은 총 3 가지 단계로 나눠볼 수 있다.   

1. Hypothesis (가설)을 세우고 
2. Cost function 정의하고 
3. Gradient descent algorithm을 사용하여 cost를 작게 만드는 값을 찾는다.

였다.  

### 조금 어렵게 정리하면 이렇다.

𝟣. Hypothesis 정의 

$$H(x) = WX$$

- $WX$는 행렬로 나타낼 수 있다.

<br>

２. Cost function 정의

$$cost(W) = \frac{1}{n} \sum_{i=1}^{n} (XW - y)^2$$

<br>

𝟥. Gradient descent algorithm 

$$W = W - \alpha \frac{∂}{∂W} cost(W)$$

- $\alpha$는 learning rate라고 부르며 경사 하강을 할때 얼마나 움직일 건지를 나타낸다.  
보통 0.001과 0.0001같은 숫자를 가진다.

<br><br>

## Logistic classification

자 그럼 위에서 대충 Linear regression에 대해서 알았으니 Logistic classification에 대해서 알아보도록하자  
이 알고리즘은 classification 알고리즘 중에서 가장 정확도가 높다고 알려져 있다.  
그래서 실제 문제에서도 바로 쓰일 수 있을 만큼 좋은 성능을 가지고 있으며 정말 중요하다.  

예를 들어보자면..  
- 스펨 메일인지 아닌지  

확인하는 용도로 쓰일 수 있다.  
또한 위 문제에서는 참인지 거짓인지를 구분하기 때문에 Binary classification이라고 할 수도 있다.  

이제 이것을 기계가 학습할 수 있도록 조금 수정해보자면  
- 스펨이다 -> 1, 아니다 -> 0 

처럼 나타낼 수 있다.  
그럼 이 문제는 가설을 어떻게 해야할까?

<br>

### 가설을 세워보자

한 가지 예시로 특정 시간 이상을 공부했을 때, 합격이다 아니다를 구분하는 문제가 있다고 하자  
그럼 그 문제를 그려본다면 아래와 같을 것이다. 

<img src="/assets/img/Modeep1/classification.png" alt="." width="60%" height="70%">

아래 있는 점은 2, 3, 5시간 정도 공부한 친구들의 합격 여부이고  
위에 있는 점은 7, 8, 10시간 공부한 친구들의 합격 여부이다.  

근데 잘 보면 위 문제는 Linear regression으로 분류할 수 있을 것 같다.  
그러니 중간에 기준을 잡고, 선을 그어보자

<img src="/assets/img/Modeep1/classification_linear.png" alt="." width="60%" height="70%">

중간 기준점을 0.5라고 잡으면 0.5 이상일 때는 합격, 아닐 때는 불합격으로 구분할 수 있다.  
그런데 만약 한 친구가 공부를 50시간 이상 했다고 했을때 선을 다시 그려보면 문제가 생긴다.

<img src="/assets/img/Modeep1/classification_linear_error.png" alt="." width="60%" height="70%">

잘 보면 기준선이 오른쪽으로 조금 밀리면서 한 친구가 합격이지만 불합격으로 예측된다.  
따라서 이 문제 때문에 직선이 아닌 다른 방법으로 가설을 정의해야한다.  

`이때 가설이 가져야하는 조건은 0과 1사이의 값을 가지도록 만들어야 한다.`

<br>

### Logistic hypothesis
$$H(x) = WX$$

기존에 있던 가설과는 다르게 새롭게 정의해주어야 한다.  
어떻게 해야할까.. 

바로 `Sigmoid`를 사용하는 것이다.  

<img src="/assets/img/Modeep1/sigmoid.png" alt="." width="55%" height="55%">

식은 기존의 $H(x)$를 $z$라는 식으로 바꿔주고 계산할 수 있다.

$$z = Wx + b $$ 

$$g(z) = \frac{1}{(1 + e^{-z})}$$

위 식의 특징은 값이 정말 작다면 0에 정말 가까워지고, 정말 크다면 1에 정말 가까워지게 된다.  
또한 함수를 그려봤을 떄 S자 처럼 생겼다고 해서 Sigmoid라고 부른다.

<br>

### 따라서

따라서 우리의 가설은 아래와 같이 정리할 수 있다.

$$H(X) = WX$$

$$H(X) = \frac{1}{(1 + e^{-(WX)})}$$


이제 다음 글에서는 위 가설로 어떻게 cost를 minimize하고 cost를 구하는지 정리해보록 하겠다.  
또한 오늘 글에 적었던 Sigmoid 말고도 다양한 함수들이 있는데, 그것은 원리라는 카테고리의 글에 적어보도록 하겠다.