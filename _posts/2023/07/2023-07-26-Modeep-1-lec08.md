---
title: 모딥 시즌 1 - ML lec 08 - (1 ~ 2)
date: '2023-07-26 15:21:00 +0900'
categories: [2. Machine Learning & DeepLearning, 2 - 1 모두를 위한 딥러닝 시즌 1 정리]
tags: [모두를 위한 딥러닝 시즌 1]
math: true
---

# lec 08 전체 정리 

<br>

## 희망이 보인다?

이번 글에서는 딥러닝의 역사에 대해서 정리해보도록 하겠다.  

딥러닝은 사람이 할 수 있는 일을 기계가 해주면 어떨까? 라는 생각에서부터 시작되었다.  
그럼 뭐부터 해야할까 바로 사람의 뇌 구조를 알아보는 것이다.  

사람의 뇌 구조는 아래와 같이 생겼다.  
이 하나를 `뉴런`이라고 부른다.  

<img src="/assets/img/Modeep1/brain.png" alt="." width="60%" height="60%"> 

막상 보면 정말 복잡해 보이지만, 실제로는 정말 단순하다.  
그냥 앞에 있는 여러개의 뉴런의 출력값을 그대로 받아서 어떤 계산을 거친 후 똑같이 다음 뉴런에  
주면 되는 원리이다.  

<img src="/assets/img/Modeep1/activation function.png" alt="." width="60%" height="60%"> 

식으로 보면 앞에서 받은 뉴런과 얼마나 중요한지를 나타내는 값 $W$를 서로 곱해서 편향 $b$ 값을 더해준 뒤   
이것을 다하고, 활성화 함수 Activation function을 통해서 다음 뉴런으로 넘겨주기만 하면 된다.  

Activation function은 뉴런의 출력값이 1이상이면 다음 뉴런에게 즁요하다(1) 로 주고 그 아래면 중요하지않아(0)  
이런식으로 값을 정해주는 함수라고 생각하면 된다.  

<img src="/assets/img/Modeep1/ann.png" alt="." width="60%" height="60%"> 

그리고 위 뉴런들을 여러개로 나열하면 왼쪽은 전 글에서 정리했던 모양이되고 오른쪽은 실제 뉴런을 노드와 엣지로 표현한  
형태가 될 것이다.  

이렇게 점점 잘되니 사람들은 언젠가는 곧 걷기도하고, 말도하고, 생각도하고, ... 이런식으로 많은 말들을 하였다.  
그리고 이때 한 논문이 나오게 된다.  

<br>

## 1차 암흑기 
컴퓨터가 AND, OR의 문제를 풀 수 있다는 논문과 동시에 컴퓨터는 여기까지가 한계라는 논문이 나오게 된다.  
내용은 컴퓨터가 AND, OR같은 문제는 선 하나로 간단하게 풀 수 있지만  
XOR을 풀 때는 선이 꾸불하게 휘면서 여러개의 퍼셉트론을 사용해야하는데 어떻게 학습 시킬지 모르겠다는 내용이였다.   
그래서 이때 조금 분위기가 좋지 않았다.  

그리고 이 분위기를 완전히 터뜨린건 1969년 MIT에 있는 한 교수님이 책을 썼는데  
이 책의 내용에는 "나는 여러가지 시도를 해봤지만 절대 모델을 학습시킬 수 없었다." 라는 말이 적혀있었다.  
그래서 이때 이후로는 모든 연구가 중지되었으며 20년동안 연구가 미뤄지게 되었다.  

<br>

## 문제가 해결되다.  
이 문제는 1986년에서야 해결되었다.  
실제로는 1974년과 1984년에 문제를 해결하였지만 그 당시에는 이런 논문들이 인기가 많이 없었다.  
그래서 많은 시간이 지난 1986년에 `Hinton`이라는 교수님에 의해서 발견되게 되었다.  

- 1986 Hinton  
방법은 Back propagation을 사용하는 것인데, Back propagation이란 오차값을 뒤에서 부터 앞으로 보내는 방법을 의미한다.  

- 1990 LeCun 
라쿤이라는 교수님은 다르게 접근하여 고양이가 물체를 볼 때 어떤 방식으로 보는지 관찰하였다.  
고양이가 물체를 볼 때는 각각의 관점에서 볼 때마다 뉴런이 다르게 동작한다는 사실을 알았고 가장 유명한 CNN을 만들게 되었다.


<br>

하지만 이 과정에서도 또 문제가 생겼다.  
그건 바로 층이 많으면 많을 수록 Backpropagation이 값을 뒤로 전달 할 때  완전 작아지게 된다는 것이다.  

그래서 다시 이때 2차 암흑기에 들어간다.

<br>

## 2차 암흑기
2차 암흑기에 들어왔을 때 Hinton 교수님한테 한 단체가 접근했다.  
그 단체는 CIFAR이라는 단체였고, Hinton 교수님의 연구비를 모두 지원해준다고 하였다.  
그래서 Hinton 교수님은 단체가 있는 캐나다로 떠나서 연구를 계속하였다.   

10년이 지난 2006과 2007년 한 논문이 나오게 된다.  
그 논문은 지금까지 학습이 안되던게 아니라 초깃값 $W$를 잘못잡았다 라는 말이였다.  
그리고 위 논문을 제출할 때 Neural networks라고 하면 사람들이 쳐다도 보지 않을것이 뻔하기 때문에  
이름을 Deep learning로 바꾸게 되었다.  

만약 CIFAR이라는 단체가 없었더라면 지금의 Deep learning은 존재하지 않았을 것이다.

<br>

## 암흑기가 끝난 후 

컴퓨터 비전 분야에서는 ImageNet 이라는 한 가지 챌린지가 존재한다.  
그것은 이미지를 맞추는데 얼마나 잘 맞추는지를 가르는 챌린지였고 2010, 2011년에는 에러가 조금씩 내려갔지만  
2012년 한 가지 사건이 발생한다.  

- AlexNet의 등장  
위 AlexNet이 등장한 2012년 에러율이 전년도 반에 가깝게 줄어든 모델이다.   
26.2 % -> 15.3%로 낮춰지고 정확도는 63%  
CNN 기반의 모델 

현재는 정확도가 대략 91%정도로 많이 좋아졌다.  