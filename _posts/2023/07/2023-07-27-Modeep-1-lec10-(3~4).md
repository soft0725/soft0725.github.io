---
title: 모딥 시즌 1 - ML lec 10 - (3 ~ 4)
date: '2023-07-27 19:07:00 +0900'
categories: [DeepLearning, 모두를 위한 딥러닝 시즌 1]
tags: [모두를 위한 딥러닝 시즌 1]
math: true
---

# lec 10 - 3~4 정리  
앞 글 10-2에서 이어집니다.
이번 글에서는 dropout과 모델 앙상블에 대해서 알아보도록 하겠다.  

## Overfitting  
저번에 말했던 Overfitting은 실전에서는 약하고 훈련에서는 강한 모델이리고 말했다.  
예를 들자면 수학문제집 모든 페이지 다 맞았는데 수능에서는 50점인것과 같다,  

따라서 이 문제를 `Regularization`으로 풀 수 있고, 코드로는 아래와 같이 구현 가능하다.  

```python
l2reg = 0.001 * tf.reduce_sum(tf.square(W))
```

## Dropout 

이 방법은 정말 특이한데 모델이 학습할 때 모든 노드를 다 연결하지말고 몇개만 연결하고 나머지는 끊어버리자는 방법이다.  

<img src="/assets/img/Modeep1/dropout.png">

오른쪽이 dropout을 적용한 모습이다.  
그럼 저걸로 어떻게 학습을 시킬까?  

방법은 진짜 간단한데 학습을 할 때 몇 개의 노드는 죽여놓고 몇 개의 노드만 활성화 시켜서 고양이를 예로 들자면   
꼬리에 대한, 귀에 대한 을 학습한 노드를 구할 수 있는데 이러면 일반 모델과 별 차이가 없다는 것이다.   

그럼 학습시킬 때는 노드를 죽여놓고 학습하고 실제로 모델을 테스트 할때는 모든 노드를 살려서 예측할 수 있다.   
그리고 학습 시킬 때 죽이는 노드를 랜덤한 값으로 죽인다.  

## Ensemble 

이것은 데이터와 기계가 많을 때 사용할 수 있는 방법이다.  
어떤 방법이냐면 Training set을 여러개를 나눠서 하나의 컴퓨터에 각각 학습을 시키는 방법이다.  
그리고 나면 기계의 갯수만큼 모델이 나오게 되는데 마지막으로 이 모델들을 전부 합쳐서 하나의 모델로 만든다.  
그러면 더 좋은 결과를 낼 수 있다.  

많게는 4% ~ 5%정도 효과를 볼 수 있다고 한다.  

## lec 10 - 4
10 - 4는 그림으로 그리고 어떤 모델인지 설명하는 과정이 너무 많아서 10-4는 따로 하지 않도록 하겠다.  
따라서 이 파트는 내가 따로 모델을 구현해보는 시간에 더 자세하게 여러개로 나누어 정리하는게 나을 것 같다.